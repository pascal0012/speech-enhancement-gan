{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply a U-Net with the size of the generator to solve the task directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Union\n",
    "\n",
    "import torch\n",
    "\n",
    "from src.data.dataloader import get_loader\n",
    "from src.data.dataset import SpeechData\n",
    "from src.data.files import write_model\n",
    "from src.data.filesampler import sample_filepaths\n",
    "from src.eval.testing import Tester\n",
    "from src.networks.unet_1D import UNet_1D\n",
    "from src.util.consts import LOG_INTERVAL, TEST_TASK_1\n",
    "from src.util.logger import Logger\n",
    "from src.util.signals import load_chunks_pair_list\n",
    "\n",
    "\n",
    "class Unet:\n",
    "    def __init__(\n",
    "        self,\n",
    "        levels: List[str],\n",
    "        hyperparameters: Dict[str, Union[int, float]],\n",
    "        device: torch.device,\n",
    "        val_paths: List[str] = None,\n",
    "    ) -> None:\n",
    "        self.levels = levels\n",
    "        self.hyperparameters = hyperparameters\n",
    "        self.device = device\n",
    "        self.tags = []\n",
    "\n",
    "        # Initialize dataset\n",
    "        self.val_paths = (\n",
    "            sample_filepaths(tasks=levels, sample_rate=0.005)\n",
    "            if val_paths is None\n",
    "            else val_paths\n",
    "        )\n",
    "        self.val_chunks = load_chunks_pair_list(self.val_paths)\n",
    "\n",
    "        dataset = SpeechData(tasks=levels, ignore_paths=self.val_paths)\n",
    "\n",
    "        self.train_loader = get_loader(\n",
    "            dataset, batch_size=hyperparameters[\"batch_size\"], device=device\n",
    "        )\n",
    "\n",
    "        # Initialize networks\n",
    "        self.network = UNet_1D(device=device)\n",
    "\n",
    "        # Compile models if on GPU\n",
    "        if device.type == \"cuda\":\n",
    "            torch.set_float32_matmul_precision(\"high\")\n",
    "            self.network = torch.compile(self.network)\n",
    "            print(\"Compiled network!\")\n",
    "\n",
    "        # Initialize optimizers\n",
    "        self.optimizer = torch.optim.AdamW(\n",
    "            self.network.parameters(), lr=hyperparameters[\"lr\"]\n",
    "        )\n",
    "\n",
    "        self.reconstruction_loss = torch.nn.MSELoss()\n",
    "\n",
    "\n",
    "    def learn(\n",
    "        self,\n",
    "        num_episodes: int = 2000,\n",
    "        sweep: bool = False,\n",
    "        disable_testing: bool = False,\n",
    "    ):\n",
    "        # Initialize logger\n",
    "        self.logger = Logger(\n",
    "            tasks=self.levels,\n",
    "            hyperparameters=self.hyperparameters,\n",
    "            tags=[\"segan\"] + self.tags,\n",
    "            sweep=sweep,\n",
    "            val_paths=self.val_paths,\n",
    "        )\n",
    "        self.tester = Tester(\n",
    "            run_name=self.logger.run_name,\n",
    "            paths=self.val_paths,\n",
    "            chunks=self.val_chunks,\n",
    "            device=self.device,\n",
    "            disable_testing=disable_testing,\n",
    "            write_all=True,\n",
    "        )\n",
    "\n",
    "        for episode in range(num_episodes):\n",
    "            for i, (clean_files, recorded_files, _) in enumerate(self.train_loader):\n",
    "                clean_files = clean_files.to(self.device, non_blocking=True)\n",
    "                recorded_files = recorded_files.to(self.device, non_blocking=True)\n",
    "\n",
    "                # Update generator\n",
    "                self.network.zero_grad(set_to_none=True)\n",
    "                g_out = self.network(recorded_files)\n",
    "                generator_loss = self.reconstruction_loss(g_out, clean_files)\n",
    "\n",
    "                generator_loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                if i % LOG_INTERVAL == 0:\n",
    "                    self.logger.log_metrics(\n",
    "                        generator_loss=generator_loss.item(),\n",
    "                        episode=episode,\n",
    "                        iteration=i,\n",
    "                        lr=0.0001,\n",
    "                    )\n",
    "\n",
    "            if episode % 80 == 0:\n",
    "                (\n",
    "                    chunk_recon_loss,\n",
    "                    mean_cer,\n",
    "                    cers,\n",
    "                    sample_paths,\n",
    "                    transcriptions,\n",
    "                ) = self.tester.test(\n",
    "                    generator=self.generator,\n",
    "                    episode=episode,\n",
    "                )\n",
    "\n",
    "                self.logger.log_metrics(\n",
    "                    chunk_recon_loss=chunk_recon_loss,\n",
    "                    mean_cer=mean_cer,\n",
    "                    cers=cers,\n",
    "                    episode=episode,\n",
    "                    iteration=i,\n",
    "                    lr=self.gen_scheduler.get_last_lr()[0],\n",
    "                    audio_paths=sample_paths,\n",
    "                    transcriptions=transcriptions,\n",
    "                )\n",
    "\n",
    "                self.write(episode=episode)\n",
    "\n",
    "        self.logger.finish()\n",
    "\n",
    "    def test(self):\n",
    "        # Validation result\n",
    "        val_results = self.tester.test(\n",
    "            generator=self.generator,\n",
    "            paths=self.val_paths,\n",
    "            chunks=self.val_chunks,\n",
    "            episode=\"final_validation\",\n",
    "            device=self.device,\n",
    "            write_all=True,\n",
    "        )\n",
    "\n",
    "        # Test results\n",
    "        self.test_paths = sample_filepaths(TEST_TASK_1, sample_rate=1)\n",
    "        test_chunks = load_chunks_pair_list(sampled_paths=self.test_paths)\n",
    "        test_results = self.tester.test(\n",
    "            generator=self.generator,\n",
    "            paths=self.test_paths,\n",
    "            chunks=test_chunks,\n",
    "            episode=\"final_testing\",\n",
    "            device=self.device,\n",
    "            write_all=True,\n",
    "        )\n",
    "\n",
    "        return val_results, test_results\n",
    "\n",
    "    def write(self, episode: int = None):\n",
    "        name_prefix = f\"episode_{episode}_\" if episode is not None else \"\"\n",
    "\n",
    "        write_model(\n",
    "            model=self.generator,\n",
    "            run_name=self.logger.run_name,\n",
    "            model_name=f\"{name_prefix}generator\",\n",
    "        )\n",
    "        write_model(\n",
    "            model=self.discriminator,\n",
    "            run_name=self.logger.run_name,\n",
    "            model_name=f\"{name_prefix}discriminator\",\n",
    "        )\n",
    "        write_model(\n",
    "            self.generator_optimizer,\n",
    "            run_name=self.logger.run_name,\n",
    "            model_name=f\"{name_prefix}generator_optimizer\",\n",
    "        )\n",
    "        write_model(\n",
    "            self.discriminator_optimizer,\n",
    "            run_name=self.logger.run_name,\n",
    "            model_name=f\"{name_prefix}discriminator_optimizer\",\n",
    "        )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
